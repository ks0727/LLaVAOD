import sys
grounding_dino_path = "/po4/ksakai/models/GroundingDINO/"
sys.path.append(grounding_dino_path)

from groundingdino.util.inference import load_model,load_image,predict,annotate
import torch
from PIL import Image
import warnings
from typing import Union

class GroundingDino:
    def __init__(self,model_path:str,weight_path:str,bbox_threshold:float,text_threshold:float,max_num_objects:int):
        """
        Args
            model_path (str): the path to grounding dino
            weight_path(str) : the path to the weight of grounding dino
            bbox_threshold (float) : bounding box threshold to predict bounding  boxes.
            text_threshold (fload) : text threshold to predict bounding boxes.
        """
        self.model_path = model_path
        self.weight_path = weight_path
        self.bbox_threshold = bbox_threshold
        self.text_threshold = text_threshold
        self.max_num_objects = max_num_objects
        try:
            self.model = load_model(model_path,weight_path)
        except Exception  as e:
            print(e)
            warnings.warn("could not load the grounding dino model.please make sure that model path and weight path are correct.")
            exit(-1)

    def get_bboxes(self,image_path,object_list:Union[list,str],is_original_size:bool=False):
        """
        --------------------------------------------------------------------
        Input
            object_list(list,str) : the list of objects that was appeared in the
            prompt. (should be generated by MLLM)
        ---------------------------------------------------------------------
        Return
            object_bboxes(list of dist) : [{label:the name of the object, bbox:bounding box value}]
        ---------------------------------------------------------------------
        """
        if isinstance(object_list,str):
            object_list = [object_list]

        assert type(object_list) == list, ("object list is supposed to be the list, please make sure the type of the object list is either 'str' or 'list'.")

        if len(object_list) > self.max_num_objects:
            print("There are too many objects to search. please reduce the amount of number of objects.")
            return None
        image_source,image = load_image(image_path)
        
        object_bboxes = []
        for _object in object_list:
            bboxes,logits,phrases = predict(
                model=self.model,
                image=image,
                caption=_object,
                box_threshold=self.bbox_threshold,
                text_threshold=self.text_threshold
            )
            if isinstance(bboxes,torch.Tensor):
                bboes = bboxes.tolist()

            if is_original_size:
                image_pil = Image.open(image_path)
                original_width,original_height, = image_pil.size
                bboxes = self.get_bounding_box_on_original_image(
                    normalized_bounding_box=bboxes,
                    original_height=original_height,
                    original_width=original_width)

            object_bboxes.append(dict(label=_object,bounding_boxes=bboxes))

        return object_bboxes
    
    #grounding dinoはnormalizedされたbboxを出力するので, それを元に戻す
    def get_bounding_box_on_original_image(self,normalized_bounding_box,original_height:int,original_width:int):
        
        if isinstance(normalized_bounding_box,torch.Tensor):
            normalized_bounding_box = normalized_bounding_box.tolist()
            #normalized_bounding_box = normalized_bounding_box.to('cpu').detach().numpy().copy()

        if type(normalized_bounding_box) is not list:
            normalized_bounding_box = [normalized_bounding_box]
        
        original_bboxes = []
        for box in normalized_bounding_box:
            center_x,center_y,width,height = box

            box_width = width*original_width
            box_height = height*original_height

            x_min = (center_x*original_width) - (box_width/2)
            y_min = (center_y*original_height) - (box_height/2)
            
            x_max = (center_x*original_width) + (box_width/2)
            y_max = (center_y*original_height) + (box_height/2)
            
            original_bboxes.append((x_min,y_min,x_max,y_max))
        
        return original_bboxes



